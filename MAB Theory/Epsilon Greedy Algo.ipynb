{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedy:\n",
    "    \n",
    "    def __init__(self, counts, values, e):   \n",
    "        self.counts = counts   # Count of times every arm is pulled \n",
    "        self.values = values # Reward of each arm\n",
    "        self.epsilon = e\n",
    "        self.arms = len(self.counts)\n",
    "    \n",
    "    def initialize(self, arms):\n",
    "        self.arms = arms\n",
    "        self.counts = [0 for i in range(arms)]\n",
    "        self.values = [0.0 for i in range(arms)]\n",
    "        \n",
    "    def select_arm(self):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            return np.argmax(self.values)\n",
    "        else:\n",
    "            return np.random.randint(self.arms)\n",
    "    \n",
    "    def update(self, arm_idx, reward):\n",
    "        self.counts[arm_idx] += 1\n",
    "        n = self.counts[arm_idx]\n",
    "        self.values[arm_idx] = (self.values[arm_idx]*(n-1) + reward)/n\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = EpsilonGreedy([], [], 0.2)\n",
    "algo.initialize(3, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monte Carlo Simulations for Epsilon Greedy Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bernauli Arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BernauliArm:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "    \n",
    "    def draw(self):\n",
    "        return np.int(np.random.random() < self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_values = [0.1,0.1,0.1,0.9,0.1]\n",
    "np.random.shuffle(p_values)\n",
    "arms = map(lambda(p): BernauliArm(p), p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print arms[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_algo(algo, arms, num_sims, horizon):\n",
    "    chosen_arm = [0 for i in range(num_sims*horizon)]   \n",
    "    reward = [0.0 for i in range(num_sims*horizon)]\n",
    "    cum_reward = [0.0 for i in range(num_sims*horizon)]  \n",
    "    times = [0.0 for i in range(num_sims*horizon)]     \n",
    "    sim_nums = [0.0 for i in range(num_sims*horizon)]  \n",
    "    \n",
    "    algo = EpsilonGreedy([], [], 0)\n",
    "    algo.initialize(len(arms))\n",
    "    \n",
    "    for sim in range(num_sims):\n",
    "        sim+=1\n",
    "        index = (sim-1)*horizon\n",
    "        np.random.shuffle(arms)\n",
    "        \n",
    "        for t in range(horizon):\n",
    "            t+=1\n",
    "            index = index + t-1\n",
    "            times[index] = t\n",
    "            chosen_arm[index] = algo.select_arm()\n",
    "            sim_nums[index] = sim\n",
    "            reward[index] = algochosen_arm[index].draw()\n",
    "            if t == 1:\n",
    "                cum_reward[index] = reward\n",
    "            else:\n",
    "                cum_reward[index] = reward + cum_reward[index - 1]\n",
    "                \n",
    "            algo.update(chosen_arm[index], reward)\n",
    "    \n",
    "    return [sim_nums , times, chosen_arms, reward, cum_reward]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
